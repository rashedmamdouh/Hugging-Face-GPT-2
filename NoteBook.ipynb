{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYrvZX5zmv9q"
   },
   "outputs": [],
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZQ1wa2Wmv9r"
   },
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]\n",
    "!apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "TqFI7Ix8Ff4X",
    "outputId": "ced74a18-f53b-4c54-b958-0fc1a38bade1"
   },
   "outputs": [],
   "source": [
    "#Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-jBbZTZPCxF"
   },
   "outputs": [],
   "source": [
    "#Import the train and test data from huggingface \n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")\n",
    "ds_valid = load_dataset(\"huggingface-course/codeparrot-ds-valid\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "NIgTdCHXmv9v",
    "outputId": "33e7de25-2b19-4d10-9394-a0fa26dd00a6"
   },
   "outputs": [],
   "source": [
    "#Select 50k from the imported train data randomly to be as the our train data and 500 for validation\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": ds_train.shuffle(seed=42).select(range(50000)),\n",
    "        \"valid\": ds_valid.shuffle(seed=42).select(range(500))\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSAv4EH-mv9v"
   },
   "outputs": [],
   "source": [
    "# show the first 200 characters of each field:\n",
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpIarKw0mv9v"
   },
   "outputs": [],
   "source": [
    "#Show Sample of working\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262,
     "referenced_widgets": [
      "4c2c89fcd7ab4283ab93de8c448adc96",
      "84f38d61385947e68832f76125a00d28",
      "4a388a74d7c443689c3e51dafbbadaf4",
      "587d48f1a83b438c9b069b23c25665d0",
      "c6b5d150b9f2426fb003ec977d77605c",
      "897a64dd81bc4cb986cfd56fa7a46f25",
      "943f407df7aa454081c0224f4ace830c",
      "191747d2d2bb4fe3b07e98e3c6127701",
      "ebff24e93e7d4a0aa9ad3636fb45f202",
      "5f3b1cf0595d409a915906d4801eeecd",
      "80f5a318003e4f6f957c00f6a01fb892",
      "1c260952b6254622b69df25a9d3d832d",
      "57c356d71a1840028c11d27a1e2829c2",
      "73e0c8f22f8443a1a04caff72dadcc65",
      "d64ed98831f14f7a88c740d0bbe03dbd",
      "7fd86d927d354e619c23863af38918a8",
      "8a245c5af94d484b946f0bb291c5a20f",
      "41117ccc242444b9a1ec9cd3815582ac",
      "9b34331ac29141569f328852dbfd633a",
      "d654f89eafb9448d8eb67e6d962d0c16",
      "b4e9aed87cac454d9b873fab5ac1679b",
      "56c2655041d14d3ab9814971b445c64b"
     ]
    },
    "id": "RqRzvLHZmv9w",
    "outputId": "1c830ae5-dd4d-4962-82ee-b1c7571c4e42"
   },
   "outputs": [],
   "source": [
    "#Tokenizition Process\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"content\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NMyCsS9mv9w"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_sizse=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "8sSRgaTcmv9w",
    "outputId": "eb53c8ad-a2cc-4037-bb5c-3e94b7f3c7b5"
   },
   "outputs": [],
   "source": [
    "#Initializing a new GPT model and print model parameters\n",
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jy6zYIONmv9x"
   },
   "outputs": [],
   "source": [
    "#We can use the DataCollatorForLanguageModeling collator, which is designed specifically for language modeling. \n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "fLYDtgNimv9x",
    "outputId": "146dfd62-620e-4689-e751-b32b87b67316"
   },
   "outputs": [],
   "source": [
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sp4wriVAVP2"
   },
   "outputs": [],
   "source": [
    "#Training \n",
    "\n",
    "Possible Optimizers to try \n",
    "Optimizers = adamw_hf, adamw_torch, adamw_apex_fused, adamw_anyprecision or adafactor.\n",
    "\n",
    "modify max_steps to stop after a number of iterations\n",
    "\n",
    "modify batch size to fit into memory\n",
    "modify save every n steps to modify how often save occurs\n",
    "\n",
    "modify output_dir to a google drive path to save and load the model correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "GponpbKimv9x",
    "outputId": "f1cfae20-7eda-4ddc-e146-abcba54e0646"
   },
   "outputs": [],
   "source": [
    "# Prepare the model for  training by traning args\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/DL3/MAX_STEP/\",\n",
    "    optim= 'adamw_hf',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=100,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=2000,\n",
    "    fp16=True,\n",
    "    max_steps=3000, \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "5qF614P1-K2i",
    "outputId": "78069b7b-be6a-4bee-e8c5-cd40d556535c"
   },
   "outputs": [],
   "source": [
    "# Start Training\n",
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "9eA8AE5lAtEG",
    "outputId": "f641ce82-8a53-4bd6-c705-edf421315a6f"
   },
   "outputs": [],
   "source": [
    "#Start Evaluation\n",
    "eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wob9svZUoUBS"
   },
   "outputs": [],
   "source": [
    "#Report Perplexity and eval_results number with each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cACQFQiaBDm1",
    "outputId": "58f330ab-9e99-4af2-dd0b-e9a1bcb382df"
   },
   "outputs": [],
   "source": [
    "#Perplexity is a measurement of how well a probability distribution or probability model predicts a sample\n",
    "\n",
    "import numpy as np\n",
    "print(f\"Perplexity: {np.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bafim3nV_VLY",
    "outputId": "189f0a57-54f3-4d27-bb17-acaba66f84cf"
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UGPFWhP_xP3"
   },
   "outputs": [],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZNAtDL1tzmA"
   },
   "outputs": [],
   "source": [
    "Example to load from checkpoint \n",
    "Note: move to Drive and get Drive path first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0XuB_dNBmv9x"
   },
   "outputs": [],
   "source": [
    "#trainer.train(resume_from_checkpoint='/content/drive/MyDrive/DL3/LR/checkpoint-2100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EQbOwImtsn4"
   },
   "outputs": [],
   "source": [
    "# Test Code Prompts \n",
    "\n",
    "Model and Tokenizer must be present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDBd2Vmvmv9y",
    "outputId": "759c7143-2190-4772-d951-932ec96f3537"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device =  torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "     model=model,\n",
    "     tokenizer=tokenizer,\n",
    "      device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQkIytU2mv9y",
    "outputId": "dce0394e-0d89-4c36-b2fc-6017dfa225e6"
   },
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create scatter plot with x, y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdNM50s9mv9y",
    "outputId": "d90d427c-1062-49aa-ffb4-52984db4e81c"
   },
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create dataframe from x and y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AN4Ku9amv9y",
    "outputId": "f8c570b9-45b9-4ec5-ecce-42404880a63a"
   },
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "# dataframe with profession, income and name\n",
    "df = pd.DataFrame({'profession': x, 'income':y, 'name': z})\n",
    "\n",
    "# calculate the mean income per profession\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcLhssi-mv9z",
    "outputId": "a0a6e0b6-8a6b-49ce-ffe7-339bb2270cc7"
   },
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "# import random forest regressor from scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# fit random forest model with 300 estimators on X, y:\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "gadwuO2AGz0N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
